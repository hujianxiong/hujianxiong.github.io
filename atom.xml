<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>@HJX - SRE</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.hujianxiong.com/"/>
  <updated>2018-05-25T15:00:15.384Z</updated>
  <id>http://www.hujianxiong.com/</id>
  
  <author>
    <name>@HJX</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>部署高可用kubernetes集群-1.9.2</title>
    <link href="http://www.hujianxiong.com/2018/03/26/install-kubernetes-v1.9.2/"/>
    <id>http://www.hujianxiong.com/2018/03/26/install-kubernetes-v1.9.2/</id>
    <published>2018-03-26T07:45:33.000Z</published>
    <updated>2018-05-25T15:00:15.384Z</updated>
    
    <content type="html"><![CDATA[<h2 id="kubernetes-高用可架构"><a href="#kubernetes-高用可架构" class="headerlink" title="kubernetes 高用可架构"></a>kubernetes 高用可架构</h2><p><img src="/uploads/install-k8s-v192/ha11.png" alt="image"></p><a id="more"></a><h2 id="环境规划"><a href="#环境规划" class="headerlink" title="环境规划"></a>环境规划</h2><p><img src="/uploads/install-k8s-v192/00BD235E-CDF1-42CB-B1B5-8FCF4FFD4B4E.png" alt="一张图片"><br><img src="/uploads/install-k8s-v192/WX20180327-161325-2x.png" alt="一张图片"></p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="1-修改主机名，kubernetes集群会识别主机名，确保主机名唯一（每台节点上）"><a href="#1-修改主机名，kubernetes集群会识别主机名，确保主机名唯一（每台节点上）" class="headerlink" title="1. 修改主机名，kubernetes集群会识别主机名，确保主机名唯一（每台节点上）"></a>1. 修改主机名，kubernetes集群会识别主机名，确保主机名唯一（每台节点上）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># $&#123;hostname&#125;变量请替换成规划的主机名，比如ns.k8s.master01,ns.k8s.node01</span><br><span class="line">$ hostnamectl set-hostname $&#123;hostname&#125;</span><br></pre></td></tr></table></figure><h3 id="2-安装Docker（每台节点上）"><a href="#2-安装Docker（每台节点上）" class="headerlink" title="2. 安装Docker（每台节点上）"></a>2. 安装Docker（每台节点上）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#0.删除旧版dokcer,如果默认之前yum安装的1.12版本,可以这样删没装可以跳过此步</span><br><span class="line">$ yum remove -y docker* </span><br><span class="line"></span><br><span class="line">#1.安装需要的包</span><br><span class="line">$ yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2   libtool-ltdl  libseccomp </span><br><span class="line">  </span><br><span class="line">#2.添加阿里云源,</span><br><span class="line">$ yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line">#3.根据实际查找当前版本 (可选)</span><br><span class="line">$ yum list docker-ce --showduplicates | sort -r</span><br><span class="line"></span><br><span class="line">#4.安装17.12.0版本</span><br><span class="line">$ yum -y install  docker-ce-17.12.0.ce </span><br><span class="line"></span><br><span class="line">#5.配置Dokcer启动参数</span><br><span class="line">$ mkdir -p /etc/docker</span><br><span class="line">$ cat &lt;&lt;EOF &gt; /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">&quot;log-opts&quot;: &#123; </span><br><span class="line">&quot;max-size&quot;: &quot;100m&quot;, </span><br><span class="line">&quot;max-file&quot;: &quot;10&quot;</span><br><span class="line"> &#125;,</span><br><span class="line">&quot;graph&quot;: &quot;/opt/data/docker/&quot;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#6.开启docker服务,和开机启动</span><br><span class="line">$ systemctl start docker &amp;&amp; systemctl enable docker</span><br></pre></td></tr></table></figure><h3 id="3-上传安装包-kubernetes1-9-2-tar-gz-到每个节点-opt-下"><a href="#3-上传安装包-kubernetes1-9-2-tar-gz-到每个节点-opt-下" class="headerlink" title="3. 上传安装包 ( kubernetes1.9.2.tar.gz )到每个节点  /opt 下"></a>3. 上传安装包 ( <font color="red">kubernetes1.9.2.tar.gz</font> )到每个节点 <font color="red"> /opt</font> 下</h3><blockquote><p>安装包下载链接: <a href="https://pan.baidu.com/s/1ejc484oTJaPi16fWbcX5_g" target="_blank" rel="noopener">https://pan.baidu.com/s/1ejc484oTJaPi16fWbcX5_g</a> 密码: snvu</p></blockquote><h4 id="3-1-解压安装包"><a href="#3-1-解压安装包" class="headerlink" title="3.1. 解压安装包"></a>3.1. 解压安装包</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar -zxvf /opt/kubernetes1.9.2.tar.gz -C /opt/ &amp;&amp; cd /opt/kubernetes1.9.2 &amp;&amp; find ./ -name &apos;._*&apos; -delete</span><br></pre></td></tr></table></figure><h4 id="3-2-安装包介绍"><a href="#3-2-安装包介绍" class="headerlink" title="3.2. 安装包介绍"></a>3.2. 安装包介绍</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">├── bin   # 所需要的kubernetes相关的bin文件</span><br><span class="line">│   ├── cfssl # 自签证书工具</span><br><span class="line">│   │   ├── cfssl</span><br><span class="line">│   │   ├── cfssl-certinfo</span><br><span class="line">│   │   └── cfssljson</span><br><span class="line">│   ├── etcd-v3.2.12-linux-amd64.tar.gz</span><br><span class="line">│   ├── kubeadm # 快速创建kubernetes集群的工具</span><br><span class="line">│   ├── kubectl # kubernetes的客户端工具，用来向集群发送命令</span><br><span class="line">│   └── kubelet # 负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理</span><br><span class="line">├── configuration # 所有的配置文件</span><br><span class="line">│   ├── dashboard # dashboard相关配置</span><br><span class="line">│   │   ├── dashboard-admin.yaml</span><br><span class="line">│   │   └── kubernetes-dashboard.yaml</span><br><span class="line">│   ├── haproxy # haproxy相关配置</span><br><span class="line">│   │   └── haproxy.cfg</span><br><span class="line">│   ├── heapster #  heapster相关yaml配置</span><br><span class="line">│   │   ├── influxdb</span><br><span class="line">│   │   │   ├── grafana.yaml</span><br><span class="line">│   │   │   ├── heapster.yaml</span><br><span class="line">│   │   │   └── influxdb.yaml</span><br><span class="line">│   │   └── rbac</span><br><span class="line">│   │       └── heapster-rbac.yaml</span><br><span class="line">│   ├── ingress # 路由配置</span><br><span class="line">│   │   ├── README.md</span><br><span class="line">│   │   ├── configmap.yaml</span><br><span class="line">│   │   ├── default-backend.yaml</span><br><span class="line">│   │   ├── namespace.yaml</span><br><span class="line">│   │   ├── provider</span><br><span class="line">│   │   │   └── baremetal</span><br><span class="line">│   │   │       └── service-nodeport.yaml</span><br><span class="line">│   │   ├── rbac.md</span><br><span class="line">│   │   ├── rbac.yaml</span><br><span class="line">│   │   ├── tcp-services-configmap.yaml</span><br><span class="line">│   │   ├── udp-services-configmap.yaml</span><br><span class="line">│   │   └── with-rbac.yaml</span><br><span class="line">│   ├── kube # kubernetes自身配置</span><br><span class="line">│   │   ├── 10-kubeadm.conf</span><br><span class="line">│   │   ├── config # kubeadm配置</span><br><span class="line">│   │   └── kubelet.service</span><br><span class="line">│   ├── net # 网络相关配置</span><br><span class="line">│   │   ├── calico-tls.yaml</span><br><span class="line">│   │   ├── calicoctl.yaml</span><br><span class="line">│   │   └── rbac.yaml</span><br><span class="line">│   └── ssl # 自签证书配置</span><br><span class="line">│       ├── ca-config.json</span><br><span class="line">│       ├── ca-csr.json</span><br><span class="line">│       └── client.json</span><br><span class="line">├── image # 依赖的所有镜像包</span><br><span class="line">│   └── images.tar</span><br><span class="line">└── shell # 初始化脚本</span><br><span class="line">    └── init.sh # 初始化节点,安装bin文件，systemd配置 , 关闭防火墙 , SELINUX等</span><br></pre></td></tr></table></figure><h4 id="3-3-节点初始化-所有节点"><a href="#3-3-节点初始化-所有节点" class="headerlink" title="3.3. 节点初始化 (所有节点) "></a>3.3. 节点初始化<font color="red"> (所有节点) </font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cd /opt/kubernetes1.9.2/shell &amp;&amp; sh init.sh</span><br></pre></td></tr></table></figure><h2 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h2><h3 id="1-自签TLS证书"><a href="#1-自签TLS证书" class="headerlink" title="1. 自签TLS证书"></a>1. 自签TLS证书</h3><h4 id="1-1-安装cfssl-cfssljson-cfssl-certinfo-在三台Master上执行"><a href="#1-1-安装cfssl-cfssljson-cfssl-certinfo-在三台Master上执行" class="headerlink" title="1.1. 安装cfssl , cfssljson , cfssl-certinfo (在三台Master上执行)"></a>1.1. 安装cfssl , cfssljson , cfssl-certinfo <font color="red">(在三台Master上执行)</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mv /opt/kubernetes1.9.2/bin/cfssl/cfssl* /usr/local/bin/</span><br><span class="line">$ chmod +x /usr/local/bin/cfssl*</span><br></pre></td></tr></table></figure><h4 id="1-2-生成ca证书-只要在Master01上执行-ca-key-pem-ca-pem-ca-csr"><a href="#1-2-生成ca证书-只要在Master01上执行-ca-key-pem-ca-pem-ca-csr" class="headerlink" title="1.2. 生成ca证书 只要在Master01上执行 (ca-key.pem,ca.pem,ca.csr)"></a>1.2. 生成ca证书 <font color="red">只要在Master01上执行 (ca-key.pem,ca.pem,ca.csr)</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd /opt/kubernetes1.9.2/configuration/ssl</span><br><span class="line">$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br></pre></td></tr></table></figure><h4 id="1-3-生成client证书-只要在Master01上执行-client-key-pem-client-pem-client-csr"><a href="#1-3-生成client证书-只要在Master01上执行-client-key-pem-client-pem-client-csr" class="headerlink" title="1.3. 生成client证书 只要在Master01上执行 (client-key.pem,client.pem,client.csr)"></a>1.3. 生成client证书 <font color="red">只要在Master01上执行 (client-key.pem,client.pem,client.csr)</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client.json | cfssljson -bare client</span><br></pre></td></tr></table></figure><h4 id="1-4-创建证书存放目录-设置PEER-NAME和PRIVATE-IP环境环境变量-在三台Master上执行"><a href="#1-4-创建证书存放目录-设置PEER-NAME和PRIVATE-IP环境环境变量-在三台Master上执行" class="headerlink" title="1.4. 创建证书存放目录,设置PEER_NAME和PRIVATE_IP环境环境变量 (在三台Master上执行)"></a>1.4. 创建证书存放目录,设置PEER_NAME和PRIVATE_IP环境环境变量 <font color="red">(在三台Master上执行)</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p /etc/kubernetes/pki/etcd</span><br><span class="line"># 注意下面eth0是你实际网卡的名字，有可能是eth1之类的。用ip addr查看。</span><br><span class="line">$ export PEER_NAME=$(hostname)</span><br><span class="line">$ export PRIVATE_IP=$(ip addr show eth0 | grep -Po &apos;inet \K[\d.]+&apos;)</span><br></pre></td></tr></table></figure><h4 id="1-5-在Master01上传输证书到Master02-Master03"><a href="#1-5-在Master01上传输证书到Master02-Master03" class="headerlink" title="1.5. 在Master01上传输证书到Master02,Master03"></a>1.5. 在Master01上传输证书到Master02,Master03</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ mv ca.pem ca-key.pem client.pem client-key.pem ca-config.json /etc/kubernetes/pki/etcd/</span><br><span class="line"></span><br><span class="line">$ scp /etc/kubernetes/pki/etcd/* root@&lt;master02-ipaddress&gt;:/etc/kubernetes/pki/etcd/</span><br><span class="line">$ scp /etc/kubernetes/pki/etcd/* root@&lt;master03-ipaddress&gt;:/etc/kubernetes/pki/etcd/</span><br></pre></td></tr></table></figure><h4 id="1-6-生成-peer-pem-peer-key-pem-server-pem-server-key-pem-在三台Master上执行"><a href="#1-6-生成-peer-pem-peer-key-pem-server-pem-server-key-pem-在三台Master上执行" class="headerlink" title="1.6 生成 peer.pem, peer-key.pem, server.pem, server-key.pem (在三台Master上执行)"></a>1.6 生成 peer.pem, peer-key.pem, server.pem, server-key.pem<font color="red"> (在三台Master上执行)</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cd /etc/kubernetes/pki/etcd</span><br><span class="line">$ cfssl print-defaults csr &gt; config.json</span><br><span class="line">$ sed -i &apos;0,/CN/&#123;s/example\.net/&apos;&quot;$PEER_NAME&quot;&apos;/&#125;&apos; config.json</span><br><span class="line">$ sed -i &apos;s/www\.example\.net/&apos;&quot;$PRIVATE_IP&quot;&apos;/&apos; config.json</span><br><span class="line">$ sed -i &apos;s/example\.net/&apos;&quot;$PEER_NAME&quot;&apos;/&apos; config.json</span><br><span class="line">$ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server config.json | cfssljson -bare server</span><br><span class="line">$ cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer config.json | cfssljson -bare peer</span><br></pre></td></tr></table></figure><h3 id="2-安装etcd集群-在三台Master上执行"><a href="#2-安装etcd集群-在三台Master上执行" class="headerlink" title="2. 安装etcd集群  (在三台Master上执行)"></a>2. 安装etcd集群 <font color="red"> (在三台Master上执行)</font></h3><h4 id="2-1-安装etcd"><a href="#2-1-安装etcd" class="headerlink" title="2.1 安装etcd"></a>2.1 安装etcd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar -zxvf /opt/kubernetes1.9.2/bin/etcd-v3.2.12-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin/</span><br></pre></td></tr></table></figure><h4 id="2-2-生成etcd的环境文件"><a href="#2-2-生成etcd的环境文件" class="headerlink" title="2.2 生成etcd的环境文件"></a>2.2 生成etcd的环境文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ touch /etc/etcd.env</span><br><span class="line">$ echo &quot;PEER_NAME=$PEER_NAME&quot; &gt;&gt; /etc/etcd.env</span><br><span class="line">$ echo &quot;PRIVATE_IP=$PRIVATE_IP&quot; &gt;&gt; /etc/etcd.env</span><br></pre></td></tr></table></figure><h4 id="2-3-创建systemd的配置文件"><a href="#2-3-创建systemd的配置文件" class="headerlink" title="2.3 创建systemd的配置文件"></a>2.3 创建systemd的配置文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">$ export ETCD0_IP=10.20.143.13</span><br><span class="line">$ export ETCD1_IP=10.20.143.14</span><br><span class="line">$ export ETCD2_IP=10.20.143.15</span><br><span class="line">$ export ETCD0_NAME=k8s-master01</span><br><span class="line">$ export ETCD1_NAME=k8s-master02</span><br><span class="line">$ export ETCD2_NAME=k8s-master03</span><br><span class="line">$ cat &gt;/etc/systemd/system/etcd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=etcd</span><br><span class="line">Documentation=https://github.com/coreos/etcd</span><br><span class="line">Conflicts=etcd.service</span><br><span class="line">Conflicts=etcd2.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=/etc/etcd.env</span><br><span class="line">Type=notify</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=5s</span><br><span class="line">LimitNOFILE=40000</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line"></span><br><span class="line">ExecStart=/usr/local/bin/etcd --name $&#123;PEER_NAME&#125; \</span><br><span class="line">    --data-dir /var/lib/etcd \</span><br><span class="line">    --listen-client-urls https://$&#123;PRIVATE_IP&#125;:2379 \</span><br><span class="line">    --advertise-client-urls https://$&#123;PRIVATE_IP&#125;:2379 \</span><br><span class="line">    --listen-peer-urls https://$&#123;PRIVATE_IP&#125;:2380 \</span><br><span class="line">    --initial-advertise-peer-urls https://$&#123;PRIVATE_IP&#125;:2380 \</span><br><span class="line">    --cert-file=/etc/kubernetes/pki/etcd/server.pem \</span><br><span class="line">    --key-file=/etc/kubernetes/pki/etcd/server-key.pem \</span><br><span class="line">    --client-cert-auth \</span><br><span class="line">    --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.pem \</span><br><span class="line">    --peer-cert-file=/etc/kubernetes/pki/etcd/peer.pem \</span><br><span class="line">    --peer-key-file=/etc/kubernetes/pki/etcd/peer-key.pem \</span><br><span class="line">    --peer-client-cert-auth \</span><br><span class="line">    --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.pem \</span><br><span class="line">    --initial-cluster $&#123;ETCD0_NAME&#125;=https://$&#123;ETCD0_IP&#125;:2380,$&#123;ETCD1_NAME&#125;=https://$&#123;ETCD1_IP&#125;:2380,$&#123;ETCD2_NAME&#125;=https://$&#123;ETCD2_IP&#125;:2380 \</span><br><span class="line">    --initial-cluster-token my-etcd-token \</span><br><span class="line">    --initial-cluster-state new</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="2-4-启动etcd集群"><a href="#2-4-启动etcd集群" class="headerlink" title="2.4. 启动etcd集群"></a>2.4. 启动etcd集群</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl start etcd</span><br><span class="line">$ systemctl enable etcd</span><br></pre></td></tr></table></figure><h4 id="2-4-验证集群状态"><a href="#2-4-验证集群状态" class="headerlink" title="2.4. 验证集群状态"></a>2.4. 验证集群状态</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ etcdctl --cert-file=/etc/kubernetes/pki/etcd/server.pem --ca-file=/etc/kubernetes/pki/etcd/ca.pem  --key-file=/etc/kubernetes/pki/etcd/server-key.pem --endpoints=https://10.20.143.13:2379,https://10.20.143.14:2379,https://10.20.143.15:2379 member list</span><br><span class="line"></span><br><span class="line"># 输出以下类似结果,集群安装成功</span><br><span class="line">6833d3ff7f25e53c: name=k8s.test.master03 peerURLs=https://10.20.143.15:2380 clientURLs=https://10.20.143.15:2379 isLeader=false</span><br><span class="line">d715f6e539919304: name=k8s.test.master02 peerURLs=https://10.20.143.14:2380 clientURLs=https://10.20.143.14:2379 isLeader=false</span><br><span class="line">e2c6d0f2545d5d78: name=k8s.test.master01 peerURLs=https://10.20.143.13:2380 clientURLs=https://10.20.143.13:2379 isLeader=true</span><br></pre></td></tr></table></figure><h3 id="3-创建kubernetes集群"><a href="#3-创建kubernetes集群" class="headerlink" title="3. 创建kubernetes集群"></a>3. 创建kubernetes集群</h3><h4 id="3-1-kubeadm配置"><a href="#3-1-kubeadm配置" class="headerlink" title="3.1. kubeadm配置"></a>3.1. kubeadm配置</h4><blockquote><p>修改配置 /opt/kubernetes1.9.2/configuration/kube/config 文件</p></blockquote><blockquote><p>apiServerCertSANs #此处填所有的masterip和lbip和其它你可能需要通过它访问apiserver的地址和域名或者主机名等</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: kubeadm.k8s.io/v1alpha1</span><br><span class="line">kind: MasterConfiguration</span><br><span class="line">apiServerCertSANs:</span><br><span class="line">- 10.20.143.12</span><br><span class="line">- 10.20.143.13</span><br><span class="line">- 10.20.143.14</span><br><span class="line">- 10.20.143.15</span><br><span class="line">- k8s-master01</span><br><span class="line">- k8s-master02</span><br><span class="line">- k8s-master03</span><br><span class="line">- k8s-node01</span><br><span class="line">- k8s-node02</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">etcd:</span><br><span class="line">  endpoints:</span><br><span class="line">  - https://10.20.143.13:2379</span><br><span class="line">  - https://10.20.143.14:2379</span><br><span class="line">  - https://10.20.143.15:2379</span><br><span class="line">  caFile: /etc/kubernetes/pki/etcd/ca.pem</span><br><span class="line">  certFile: /etc/kubernetes/pki/etcd/client.pem</span><br><span class="line">  keyFile: /etc/kubernetes/pki/etcd/client-key.pem</span><br><span class="line"></span><br><span class="line">apiServerExtraArgs:</span><br><span class="line">  apiserver-count: 3</span><br><span class="line"></span><br><span class="line">networking:</span><br><span class="line">  podSubnet: 192.168.0.0/16</span><br><span class="line">kubernetesVersion: v1.9.2</span><br><span class="line">featureGates:</span><br><span class="line">   CoreDNS: true</span><br></pre></td></tr></table></figure><h4 id="3-2-运行kubeadm"><a href="#3-2-运行kubeadm" class="headerlink" title="3.2 运行kubeadm"></a>3.2 运行kubeadm</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm init --config=/opt/kubernetes1.9.2/configuration/kube/config</span><br><span class="line">$ mkdir ~/.kube &amp;&amp; cp /etc/kubernetes/admin.conf ~/.kube/config</span><br></pre></td></tr></table></figure><blockquote><font color="red">牢记生成的 kubeadm join 命令  </font></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join --token c97226.dc9b3c8ab883b5cb 10.20.143.13:6443 --discovery-token-ca-cert-hash sha256:70e980b465032f712c06fe9ccecb116c7b2dbd4f682edf88e6627324b583a9d0</span><br></pre></td></tr></table></figure><h4 id="3-3-启动多个Master"><a href="#3-3-启动多个Master" class="headerlink" title="3.3 启动多个Master"></a>3.3 启动多个Master</h4><blockquote><font color="red">在master1上拷贝相关配置文件到master02,master03上</font></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ scp /etc/kubernetes/pki/* root@10.20.143.14:/etc/kubernetes/pki/</span><br><span class="line">$ scp /etc/kubernetes/pki/* root@10.20.143.15:/etc/kubernetes/pki/</span><br><span class="line">$ scp /opt/kubernetes1.9.2/configuration/kube/config root@10.20.143.14:/root/</span><br><span class="line">$ scp /opt/kubernetes1.9.2/configuration/kube/config root@10.20.143.15:/root/</span><br></pre></td></tr></table></figure><blockquote><font color="red">登陆master02,master03执行以下相同命令</font></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 删除pki目录下的apiserver.crt 和 apiserver.key文件</span><br><span class="line">$ cd  /etc/kubernetes/pki/</span><br><span class="line">$ rm -rf apiserver.crt apiserver.key</span><br><span class="line"># 创建master02,master03</span><br><span class="line">$ kubeadm init --config ~/config</span><br></pre></td></tr></table></figure><blockquote><p>验证master集群</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl  get nodes</span><br><span class="line">NAME                STATUS    ROLES     AGE       VERSION</span><br><span class="line">k8s.test.master01   Ready     master    2d        v1.9.2</span><br><span class="line">k8s.test.master02   Ready     master    2d        v1.9.2</span><br><span class="line">k8s.test.master03   Ready     master    2d        v1.9.2</span><br></pre></td></tr></table></figure><h4 id="3-4-启动loadbalance-在loadbalance节点上执行"><a href="#3-4-启动loadbalance-在loadbalance节点上执行" class="headerlink" title="3.4 启动loadbalance (在loadbalance节点上执行)"></a>3.4 启动loadbalance (在loadbalance节点上执行)</h4><h5 id="3-4-1-修改配置文件"><a href="#3-4-1-修改配置文件" class="headerlink" title="3.4.1 修改配置文件"></a>3.4.1 修改配置文件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">$ cat /opt/kubernetes1.9.2/configuration/haproxy/haproxy.cfg</span><br><span class="line">global</span><br><span class="line">  daemon</span><br><span class="line">  log 127.0.0.1 local0</span><br><span class="line">  log 127.0.0.1 local1 notice</span><br><span class="line">  maxconn 4096</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">  log               global</span><br><span class="line">  retries           3</span><br><span class="line">  maxconn           2000</span><br><span class="line">  timeout connect   5s</span><br><span class="line">  timeout client    50s</span><br><span class="line">  timeout server    50s</span><br><span class="line"></span><br><span class="line">frontend k8s</span><br><span class="line">  bind *:6444 #安装包中的配置文件多了一个 冒号: 注意修改!!!</span><br><span class="line">  mode tcp</span><br><span class="line">  default_backend k8s-backend</span><br><span class="line"></span><br><span class="line">backend k8s-backend</span><br><span class="line">  balance roundrobin</span><br><span class="line">  mode tcp</span><br><span class="line">  #下面三个ip替换成三个你自己master的地址</span><br><span class="line">  server k8s-0 10.20.143.13:6443 check </span><br><span class="line">  server k8s-1 10.20.143.14:6443 check </span><br><span class="line">  server k8s-2 10.20.143.15:6443 check</span><br></pre></td></tr></table></figure><h5 id="3-4-2-启动haproxy"><a href="#3-4-2-启动haproxy" class="headerlink" title="3.4.2 启动haproxy"></a>3.4.2 启动haproxy</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir /etc/haproxy </span><br><span class="line">$ cp /opt/kubernetes1.9.2/configuration/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg</span><br><span class="line">$ docker run --restart always --net=host -v /etc/haproxy:/usr/local/etc/haproxy --name k8s-haproxy -d haproxy:1.7</span><br></pre></td></tr></table></figure><h4 id="3-4-3-修改kubeproxy配置-在master01上"><a href="#3-4-3-修改kubeproxy配置-在master01上" class="headerlink" title="3.4.3 修改kubeproxy配置(在master01上)"></a>3.4.3 修改kubeproxy配置<font color="red">(在master01上)</font></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system edit configmap kube-proxy</span><br><span class="line">#找到文件的这一块，第七行server 有个ip地址</span><br><span class="line">apiVersion: v1</span><br><span class="line">    kind: Config</span><br><span class="line">    clusters:</span><br><span class="line">    - cluster:</span><br><span class="line">        certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">        server: https://10.230.204.151:6443 #修改为 LoadBalanceIP:6444</span><br><span class="line">      name: default</span><br><span class="line">    contexts:</span><br><span class="line">    - context:</span><br><span class="line">        cluster: default</span><br><span class="line">        namespace: default</span><br><span class="line">        user: default</span><br><span class="line">      name: default</span><br><span class="line">    current-context: default</span><br><span class="line">    users:</span><br><span class="line">    - name: default</span><br><span class="line">      user:</span><br><span class="line">        tokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br></pre></td></tr></table></figure><h4 id="3-5-Join-Node-节点"><a href="#3-5-Join-Node-节点" class="headerlink" title="3.5 Join Node 节点"></a>3.5 Join Node 节点</h4><blockquote><p>kubeadm join </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm join --token &lt;token&gt; 10.20.143.13:6443 --discovery-token-ca-cert-hash sha256:&lt;hash&gt;</span><br></pre></td></tr></table></figure><blockquote><font color="red">修改node节点kubelet配置</font></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ vim /etc/kubernetes/kubelet.conf </span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data: xxxxxx #此处省略几百字符</span><br><span class="line">    server: https://10.20.143.12:6444 #修改这里为LB:6444，</span><br><span class="line">  name: default-cluster</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: default-cluster</span><br><span class="line">    namespace: default</span><br><span class="line">    user: default-auth</span><br><span class="line">  name: default-context</span><br><span class="line">current-context: default-context</span><br><span class="line"></span><br><span class="line">$ systemctl restart kubelet</span><br></pre></td></tr></table></figure><h4 id="3-6-创建Calico-CNI网络-在master01上"><a href="#3-6-创建Calico-CNI网络-在master01上" class="headerlink" title="3.6 创建Calico CNI网络 (在master01上)"></a>3.6 创建Calico CNI网络 <font color="red">(在master01上)</font></h4><blockquote><p>配置calico网络需要的TLS calico-etcd-secrets</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd  /opt/kubernetes1.9.2/configuration/net</span><br><span class="line">$ sed -i &quot;s/\$ETCDCA/`cat /etc/kubernetes/pki/etcd/ca.pem | base64 | tr -d &apos;\n&apos;`/&quot; calico-tls.yaml </span><br><span class="line">$ sed -i &quot;s/\$ETCDCERT/`cat /etc/kubernetes/pki/etcd/server.pem | base64 | tr -d &apos;\n&apos;`/&quot; calico-tls.yaml </span><br><span class="line">$ sed -i &quot;s/\$ETCDKYE/`cat /etc/kubernetes/pki/etcd/server-key.pem | base64 | tr -d &apos;\n&apos;`/&quot; calico-tls.yaml</span><br></pre></td></tr></table></figure><blockquote><p>修改calico-tls.yaml中 etcd_endpoints 为上面装的etcd集群地址</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># Calico Version v3.0.4</span><br><span class="line"># https://docs.projectcalico.org/v3.0/releases#v3.0.4</span><br><span class="line"># This manifest includes the following component versions:</span><br><span class="line">#   calico/node:v3.0.4</span><br><span class="line">#   calico/cni:v2.0.3</span><br><span class="line">#   calico/kube-controllers:v2.0.2</span><br><span class="line"></span><br><span class="line"># This ConfigMap is used to configure a self-hosted Calico installation.</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: calico-config</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  # Configure this with the location of your etcd cluster.</span><br><span class="line">  etcd_endpoints: &quot;https://127.0.0.1:2379&quot; #改成正确的etcd集群地址&quot;</span><br><span class="line"></span><br><span class="line">  # Configure the Calico backend to use.</span><br><span class="line">  calico_backend: &quot;bird&quot;</span><br><span class="line"></span><br><span class="line">  # The CNI network configuration to install on each node.</span><br></pre></td></tr></table></figure><blockquote><p>安装网络</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f rbac.yaml</span><br><span class="line">$ kubectl apply -f calico-tls.yaml</span><br></pre></td></tr></table></figure><h3 id="3-7-安装监控和WEB-UI-在master01上"><a href="#3-7-安装监控和WEB-UI-在master01上" class="headerlink" title="3.7 安装监控和WEB UI (在master01上)"></a>3.7 安装监控和WEB UI (在master01上)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cd /opt/kubernetes1.9.2/configuration</span><br><span class="line">$ kubectl apply -f heapster/influxdb</span><br><span class="line">$ kubectl apply -f heapster/rbac</span><br><span class="line">$ kubectl apply -f dashboard</span><br></pre></td></tr></table></figure><blockquote><p>Web UI 访问地址: https://{node-ip}:32000</p></blockquote><h2 id="部署Ingress"><a href="#部署Ingress" class="headerlink" title="部署Ingress"></a>部署Ingress</h2><h3 id="1-架构图"><a href="#1-架构图" class="headerlink" title="1. 架构图"></a>1. 架构图</h3><p><img src="/uploads/install-k8s-v192/ingress-controller.png" alt="image"></p><h3 id="2-创建-ingress-nginx"><a href="#2-创建-ingress-nginx" class="headerlink" title="2. 创建 ingress-nginx"></a>2. 创建 ingress-nginx</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ cd /opt/kubernetes1.9.2/configuration/ingress</span><br><span class="line">$ kubectl apply -f namespace.yaml</span><br><span class="line">$ kubectl apply -f default-backend.yaml</span><br><span class="line">$ kubectl apply -f configmap.yaml</span><br><span class="line">$ kubectl apply -f tcp-services-configmap.yaml</span><br><span class="line">$ kubectl apply -f udp-services-configmap.yaml</span><br><span class="line"></span><br><span class="line">$ kubectl apply -f rbac.yaml</span><br><span class="line">$ kubectl apply -f with-rbac.yaml</span><br><span class="line"></span><br><span class="line">$ cd /opt/kubernetes1.9.2/configuration/ingress/provider/baremetal</span><br><span class="line">$ kubectl apply -f service-nodeport.yaml</span><br><span class="line">$ kubectl  get svc -n ingress-nginx</span><br><span class="line">NAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">default-http-backend   ClusterIP   10.109.228.128   &lt;none&gt;        80/TCP                       2h</span><br><span class="line">ingress-nginx          NodePort    10.97.114.177    &lt;none&gt;        80:32358/TCP,443:31164/TCP   2h</span><br></pre></td></tr></table></figure><h3 id="3-测试验证"><a href="#3-测试验证" class="headerlink" title="3. 测试验证"></a>3. 测试验证</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl run --image=nginx nginx-web01 </span><br><span class="line">$ kubectl expose deployment nginx-web01 --port=80</span><br><span class="line">$ kubectl run --image=nginx nginx-web02 </span><br><span class="line">$ kubectl expose deployment nginx-web02 --port=80</span><br><span class="line">$ cat &lt;&lt;EOF &gt; nginx-web-test.yaml  </span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-http-test</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: web01.test.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">        - backend:</span><br><span class="line">            serviceName: nginx-web01</span><br><span class="line">            servicePort: 80</span><br><span class="line">  - host: web02.test.com</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">        - backend:</span><br><span class="line">            serviceName: nginx-web02</span><br><span class="line">            servicePort: 80</span><br><span class="line">EOF</span><br><span class="line">$ kubectl apply -f  nginx-web-test.yaml</span><br></pre></td></tr></table></figure><blockquote><p>LB配置,将域名解析至lb或者绑定hosts,后访问域名即可.</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">frontend http-test</span><br><span class="line">  bind *:80</span><br><span class="line">  mode tcp</span><br><span class="line">  default_backend http-test</span><br><span class="line"></span><br><span class="line">backend http-test</span><br><span class="line">  balance roundrobin</span><br><span class="line">  mode tcp</span><br><span class="line">  server k8s-0 10.20.143.13:32358 check</span><br><span class="line">  server k8s-1 10.20.143.14:32358 check</span><br><span class="line">  server k8s-2 10.20.143.15:32358 check</span><br></pre></td></tr></table></figure><p>Done.</p><hr><blockquote><p>参考:<br><br><a href="https://kubernetes.io/docs/setup/independent/high-availability/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/high-availability/</a><br><br><a href="https://segmentfault.com/a/1190000013262609?spm=5176.730006-cmxz025618.102.7.HmMX5q" target="_blank" rel="noopener">https://segmentfault.com/a/1190000013262609?spm=5176.730006-cmxz025618.102.7.HmMX5q</a><br><br><a href="https://segmentfault.com/a/1190000013611571" target="_blank" rel="noopener">https://segmentfault.com/a/1190000013611571</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;kubernetes-高用可架构&quot;&gt;&lt;a href=&quot;#kubernetes-高用可架构&quot; class=&quot;headerlink&quot; title=&quot;kubernetes 高用可架构&quot;&gt;&lt;/a&gt;kubernetes 高用可架构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/uploads/install-k8s-v192/ha11.png&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="docker" scheme="http://www.hujianxiong.com/categories/docker/"/>
    
      <category term="kubernetes" scheme="http://www.hujianxiong.com/categories/docker/kubernetes/"/>
    
    
      <category term="docker" scheme="http://www.hujianxiong.com/tags/docker/"/>
    
      <category term="kubernetes" scheme="http://www.hujianxiong.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>基于Prometheus+Grafana监控Swarm Mode/MySQL</title>
    <link href="http://www.hujianxiong.com/2017/08/03/prometheus-Grafana-docker-swarm-mode/"/>
    <id>http://www.hujianxiong.com/2017/08/03/prometheus-Grafana-docker-swarm-mode/</id>
    <published>2017-08-03T06:45:33.000Z</published>
    <updated>2018-05-25T15:02:16.151Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装Prometheus服务端"><a href="#安装Prometheus服务端" class="headerlink" title="安装Prometheus服务端"></a>安装Prometheus服务端</h2><h3 id="1-创建数据目录"><a href="#1-创建数据目录" class="headerlink" title="1.创建数据目录"></a>1.创建数据目录</h3><pre><code>mkdir -p /yschome/data/prometheus/etc /yschome/data/prometheus/data</code></pre><h3 id="2-创建配置文件"><a href="#2-创建配置文件" class="headerlink" title="2.创建配置文件"></a>2.创建配置文件</h3><a id="more"></a><pre><code>cat &lt;&lt; EOF &gt; /yschome/data/prometheus/etc/prometheus.yml global:  scrape_interval:     15s  evaluation_interval: 15sscrape_configs:  - job_name: &apos;container&apos;    static_configs:    - targets: [&apos;10.20.140.104:9090&apos;,,&apos;10.20.140.105:9090&apos;]      labels:        instance: cadvisor  - job_name: &apos;node&apos;    static_configs:    - targets: [&apos;10.20.140.104:9100&apos;]      labels:        instance: 10.20.140.104    - targets: [&apos;10.20.140.105:9100&apos;]      labels:        instance: 10.20.140.105  - job_name: prometheus    static_configs:    - targets: [&apos;10.20.140.103:9090&apos;]      labels:        instance: prometheus  - job_name: &apos;linux&apos;    static_configs:    - targets: [&apos;10.20.102.91:9100&apos;]      labels:        instance: test05_cadb    - targets: [&apos;10.20.102.92:9100&apos;]      labels:        instance: test05_psmsdb  - job_name: &apos;mysql&apos;    static_configs:    - targets: [&apos;10.20.102.91:9104&apos;]      labels:        instance: test05_cadb    - targets: [&apos;10.20.102.92:9104&apos;]      labels:        instance: test05_psmsdbEOF</code></pre><h3 id="3-使用docker启动服务端"><a href="#3-使用docker启动服务端" class="headerlink" title="3.使用docker启动服务端"></a>3.使用docker启动服务端</h3><blockquote><p>开放9090端口,挂载前面创建的数据目录</p></blockquote><pre><code>docker run -d -p 9090:9090 --restart always  \-v /yschome/data/prometheus/etc/:/etc/prometheus/ \-v /yschome/data/prometheus/data/:/prometheus/ \-v /etc/localtime:/etc/localtime --name prometheus \ 10.20.145.240/devrepo/prometheus:v1.0</code></pre><h2 id="安装Prometheus-exporter监控端"><a href="#安装Prometheus-exporter监控端" class="headerlink" title="安装Prometheus exporter监控端"></a>安装Prometheus exporter监控端</h2><blockquote><p>监控Docker Swarm Mode 集群<br> swarm mode 集群所有的宿主机都需要装2个exporter</p></blockquote><h3 id="1-node-exporter"><a href="#1-node-exporter" class="headerlink" title="1.node_exporter"></a>1.node_exporter</h3><pre><code>#使用docker安装node_exporter获取的数据有问题(可能是我使用了ingree网络导致数据采集了多次),所以采用二进制安装 cd /opt &amp;&amp; wget http://download.ys-city.com/prometheus/node_exporter-0.14.0.linux-amd64.tar.gz mkdir  prometheus_exporters  tar -zxvf node_exporter-0.14.0.linux-amd64.tar.gz -C /opt/prometheus_exporters  --strip-components=1#启动 nohup /opt/prometheus_exporters/node_exporter &amp;</code></pre><h3 id="2-cadvisor"><a href="#2-cadvisor" class="headerlink" title="2.cadvisor"></a>2.cadvisor</h3><pre><code>#使用docker swarm mode global部署cadvisordocker service create --mode=global  --network=&quot;my-net&quot; \--endpoint-mode=vip  \--restart-condition=any   \-name=cadvisor  \--mount  type=bind,src=/,dst=/rootfs \--mount  type=bind,src=/var/run,dst=/var/run\--mount  type=bind,src=/sys,dst=/sys \--mount  type=bind,src=/yschome/data/docker/,dst=/rootfs \ 10.20.145.240/library/cadvisor:v1.0</code></pre><blockquote><p>监控MySQL<br>在MySQL宿主机上安装2个exporter,均采用二进制安装 </p></blockquote><h3 id="1-node-exporter-1"><a href="#1-node-exporter-1" class="headerlink" title="1.node_exporter"></a>1.node_exporter</h3><pre><code>cd /opt &amp;&amp; wget http://download.ys-city.com/prometheus/node_exporter-0.14.0.linux-amd64.tar.gz mkdir  prometheus_exporters  tar -zxvf node_exporter-0.14.0.linux-amd64.tar.gz -C /opt/prometheus_exporters  --strip-components=1#启动 nohup /opt/prometheus_exporters/node_exporter &amp;</code></pre><h3 id="2-mysqld-exporter"><a href="#2-mysqld-exporter" class="headerlink" title="2.mysqld_exporter"></a>2.mysqld_exporter</h3><pre><code>cd /opt &amp;&amp; wget http://download.ys-city.com/prometheus/mysqld_exporter-0.10.0.linux-amd64.tar.gztar -zxvf mysqld_exporter-0.10.0.linux-amd64.tar.gz -C /opt/prometheus_exporters  --strip-components=1mkdir -p /usr/local/services/prometheus_exporters /opt/prometheus #配置数据库授权账号,mysqld_exporter使用此账号收集数据库信息cat &lt;&lt; EOF &gt; /usr/local/services/prometheus_exporters/.my.cnf[client]user=rootpassword=rootEOF#启动nohup /opt/prometheus_exporters/mysqld_exporter -config.my-cnf=&quot;/usr/local/services/prometheus_exporters/.my.cnf&quot; &amp;</code></pre><p>##安装Grafana图表</p><pre><code>#使用docker安装grafanadocker run -d -p 3000:3000 --restart always --name grafana-new 10.20.145.240/library/grafana:v4.4.2</code></pre><h3 id="1-配置数据源"><a href="#1-配置数据源" class="headerlink" title="1.配置数据源"></a>1.配置数据源</h3><p><img src="/uploads/prometheus-Grafana-docker-swarm-mode/datasource.png" alt="datasources"></p><h3 id="2-配置MySQL-dashboards"><a href="#2-配置MySQL-dashboards" class="headerlink" title="2.配置MySQL dashboards"></a>2.配置MySQL dashboards</h3><blockquote><p>可以直接安装Percona插件来展示MySQL监控数据<br><a href="https://grafana.com/plugins/percona-percona-app" target="_blank" rel="noopener">https://grafana.com/plugins/percona-percona-app</a><br>也可以下载percona的dashboards自己导入所需要的面板<br><a href="https://github.com/percona/grafana-dashboards.git" target="_blank" rel="noopener">https://github.com/percona/grafana-dashboards.git</a></p></blockquote><p>我使用第二种方法下载我需要的面板然后导入</p><h4 id="mysql-overview-json"><a href="#mysql-overview-json" class="headerlink" title="mysql_overview.json"></a><a href="/uploads/prometheus-Grafana-docker-swarm-mode/mysql_overview.json" target="_blank">mysql_overview.json</a></h4><blockquote><p><img src="/uploads/prometheus-Grafana-docker-swarm-mode/mysql.png" alt="mysql overview"></p></blockquote><h3 id="3-配置Swarm-Mode监控面板"><a href="#3-配置Swarm-Mode监控面板" class="headerlink" title="3.配置Swarm Mode监控面板"></a>3.配置Swarm Mode监控面板</h3><h4 id="swarm-mode-json"><a href="#swarm-mode-json" class="headerlink" title="swarm_mode.json"></a><a href="/uploads/prometheus-Grafana-docker-swarm-mode/swarm_mode.json" target="_blank">swarm_mode.json</a></h4><blockquote><p><img src="/uploads/prometheus-Grafana-docker-swarm-mode/swarm_mode.png" alt="swarm mode"></p></blockquote><h3 id="4-配置主机监控面板"><a href="#4-配置主机监控面板" class="headerlink" title="4.配置主机监控面板"></a>4.配置主机监控面板</h3><h4 id="Node-1-json"><a href="#Node-1-json" class="headerlink" title="Node-1.json"></a><a href="/uploads/prometheus-Grafana-docker-swarm-mode/node-1.json" target="_blank">Node-1.json</a></h4><blockquote><p><img src="/uploads/prometheus-Grafana-docker-swarm-mode/node-1.png" alt="node-1"></p></blockquote><h4 id="Node-2-json"><a href="#Node-2-json" class="headerlink" title="Node-2.json"></a><a href="/uploads/prometheus-Grafana-docker-swarm-mode/node-2.json" target="_blank">Node-2.json</a></h4><blockquote><p><img src="/uploads/prometheus-Grafana-docker-swarm-mode/node-2.png" alt="node-2"></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;安装Prometheus服务端&quot;&gt;&lt;a href=&quot;#安装Prometheus服务端&quot; class=&quot;headerlink&quot; title=&quot;安装Prometheus服务端&quot;&gt;&lt;/a&gt;安装Prometheus服务端&lt;/h2&gt;&lt;h3 id=&quot;1-创建数据目录&quot;&gt;&lt;a href=&quot;#1-创建数据目录&quot; class=&quot;headerlink&quot; title=&quot;1.创建数据目录&quot;&gt;&lt;/a&gt;1.创建数据目录&lt;/h3&gt;&lt;pre&gt;&lt;code&gt;mkdir -p /yschome/data/prometheus/etc /yschome/data/prometheus/data
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;2-创建配置文件&quot;&gt;&lt;a href=&quot;#2-创建配置文件&quot; class=&quot;headerlink&quot; title=&quot;2.创建配置文件&quot;&gt;&lt;/a&gt;2.创建配置文件&lt;/h3&gt;
    
    </summary>
    
      <category term="docker" scheme="http://www.hujianxiong.com/categories/docker/"/>
    
      <category term="monitor" scheme="http://www.hujianxiong.com/categories/docker/monitor/"/>
    
    
      <category term="docker" scheme="http://www.hujianxiong.com/tags/docker/"/>
    
      <category term="grafana" scheme="http://www.hujianxiong.com/tags/grafana/"/>
    
      <category term="prometheus" scheme="http://www.hujianxiong.com/tags/prometheus/"/>
    
      <category term="swarm mode" scheme="http://www.hujianxiong.com/tags/swarm-mode/"/>
    
  </entry>
  
  <entry>
    <title>Docker Swarm Calico Etcd Haproxy</title>
    <link href="http://www.hujianxiong.com/2017/03/21/install-docker-swarm-calico/"/>
    <id>http://www.hujianxiong.com/2017/03/21/install-docker-swarm-calico/</id>
    <published>2017-03-21T10:45:33.000Z</published>
    <updated>2018-05-25T15:05:12.370Z</updated>
    
    <content type="html"><![CDATA[<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><blockquote><p>参考:<a href="http://hujianxiong.com/2016/09/02/install-docker-swarm-cluster" target="_blank" rel="noopener">http://hujianxiong.com/2016/09/02/install-docker-swarm-cluster</a></p></blockquote><h2 id="安装组件"><a href="#安装组件" class="headerlink" title="安装组件"></a>安装组件</h2><ul><li>Swarm 使用原生的集群方案</li><li>Etcd key/value存储集群,网络信息等</li><li>Registrator 服务注册</li><li>Calico 网络</li><li>Consul-Haproxy 自动代理后端服务</li><li>Consul Registrator注册的地方也可以使用Etcd,不过有现成的Consul-Haproxy模板可以使用就不替换了,使用Etcd可以替换成confd-Haproxy</li></ul><a id="more"></a><h2 id="部署Master端"><a href="#部署Master端" class="headerlink" title="部署Master端"></a>部署Master端</h2><blockquote><p>部署服务etcd,calico,consul,consul-haproxy,docker-proxy,swarm-manager,docker-daemon</p></blockquote><h3 id="1-配置ENV"><a href="#1-配置ENV" class="headerlink" title="1.配置ENV"></a>1.配置ENV</h3><pre><code>ntpdate 10.20.101.251export MASTER_IP=10.20.140.2export DC=test02_dc export MASTER_HOSTNAME=docker.swarm.master01export HAPROXYDOMAIN=test02.youmenlu.com</code></pre><h3 id="2-安装Etcd"><a href="#2-安装Etcd" class="headerlink" title="2.安装Etcd"></a>2.安装Etcd</h3><pre><code>yum -y install etcdsed -i  &quot;s/ETCD_LISTEN_CLIENT_URLS=\&quot;http:\/\/localhost:2379\&quot;/ETCD_LISTEN_CLIENT_URLS=\&quot;http:\/\/0.0.0.0:2379\&quot;/&quot;  /etc/etcd/etcd.confsed  -i  &quot;s/ETCD_ADVERTISE_CLIENT_URLS=\&quot;http:\/\/localhost:2379\&quot;/ETCD_ADVERTISE_CLIENT_URLS=\&quot;http:\/\/`echo $MASTER_IP`:2379\&quot;/&quot; /etc/etcd/etcd.conf cat /etc/etcd/etcd.conf systemctl daemon-reloadsystemctl start etcdsystemctl enable etcd</code></pre><h3 id="3-安装Docker-daemon"><a href="#3-安装Docker-daemon" class="headerlink" title="3.安装Docker-daemon"></a>3.安装Docker-daemon</h3><pre><code>yum -y install docker-enginesed -i &quot;s/ExecStart=\/usr\/bin\/dockerd/ExecStart=\/usr\/bin\/dockerd -g=\/yschome\/data\/docker --insecure-registry 10.20.145.240  --registry-mirror=https:\/\/kyyfenk.mirror.acs.aliyun.com --cluster-advertise eth0:2375  --cluster-store etcd:\/\/`echo $MASTER_IP`:2379/&quot; /usr/lib/systemd/system/docker.servicesystemctl daemon-reloadsystemctl start dockersystemctl enable docker</code></pre><h3 id="4-安装Calico"><a href="#4-安装Calico" class="headerlink" title="4.安装Calico"></a>4.安装Calico</h3><pre><code>yum -y install wget wget -O /usr/local/bin/calicoctl http://download.ys-city.com/docker/calicoctl-1.1.0chmod +x /usr/local/bin/calicoctlmkdir -p /etc/calico/cat &lt;&lt;EOF &gt; /etc/calico/calicoctl.cfgapiVersion: v1kind: calicoApiConfigmetadata:spec:  datastoreType: &quot;etcdv2&quot;  etcdEndpoints: &quot;http://`echo $MASTER_IP`:2379&quot;EOFcat /etc/calico/calicoctl.cfg## calico-node:v1.1.0 官网上找这个镜像calicoctl node run  --use-docker-networking-container-labels  --docker-networking-ifprefix=eth --node-image=10.20.145.240/library/calico-node:v1.1.0calicoctl node status##配置Calico内部访问规则cat &lt;&lt; EOF | calicoctl apply -f -- apiVersion: v1  kind: policy  metadata:    name: backend  spec:    order: 0    selector: backend == &apos;true&apos;    ingress:    - action: allow      protocol: tcp      source:        selector: backend == &apos;true&apos;    - action: allow      source:      selector: backend == &apos;true&apos;  egress:  - action: allow    destination:      selector: backend == &apos;true&apos;EOF##配置外部访问规则,测试环境简单粗暴配置,生产环境需安需配置cat &lt;&lt; EOF | calicoctl apply -f -- apiVersion: v1  kind: policy  metadata:  name: domain  spec:    order: 0    ingress:    - action: allow      protocol: tcp    - action: allow    egress:    - action: allowEOF</code></pre><h3 id="5-启动容器组件"><a href="#5-启动容器组件" class="headerlink" title="5.启动容器组件"></a>5.启动容器组件</h3><pre><code>docker run -d \-p 8300:8300 \-p 8301:8301 \-p 8301:8301/udp \-p 8302:8302 \-p 8302:8302/udp \-p 8400:8400 \-p 8500:8500 \-p 8600:53 \-p 53:53/udp \-v /yschome/data/consul:/data \-h `echo $MASTER_HOSTNAME`  \--restart=always \--label registrator.ignored=true \--name=consul 10.20.145.240/library/consul:0.5.2 -server -bootstrap -ui-dir=/ui -dc=`echo $DC` -advertise 10.20.141.20 -client 0.0.0.0docker run  -d -p 80:80 --name haproxy  \--restart always  \-e HAPROXY_DOMAIN=`echo $HAPROXYDOMAIN` \-e CONSUL_CONNECT=`echo $MASTER_IP`:8500 \10.20.145.240/library/haproxy:1.1docker run -ti -d \-p 2375:2375 \--hostname=`echo $MASTER_HOSTNAME` \--restart=always \--name devops-proxy \--label registrator.ignored=true \-v /var/run/docker.sock:/var/run/docker.sock \-e PORT=2375 \10.20.145.240/library/docker-proxy:latestdocker run -ti -d \--restart=always -p 3375:3375 \--label registrator.ignored=true \--name devops-swarm-manager  10.20.145.240/library/swarm:latest  \manage  --replication \--addr `echo $MASTER_IP`:3375 \--host tcp://0.0.0.0:3375  etcd://`echo $MASTER_IP`:2379</code></pre><h3 id="6-创建集群网络"><a href="#6-创建集群网络" class="headerlink" title="6.创建集群网络"></a>6.创建集群网络</h3><pre><code>docker network create --driver calico --ipam-driver calico-ipam   my-net</code></pre><h2 id="部署Agent端"><a href="#部署Agent端" class="headerlink" title="部署Agent端"></a>部署Agent端</h2><blockquote><p>安装组件docker-daemon,calico,docker-proxy,registrator,swarm-agent</p></blockquote><blockquote><p>registrator 我fork了一份<a href="https://github.com/gliderlabs/registrator代码,做了点修改" target="_blank" rel="noopener">https://github.com/gliderlabs/registrator代码,做了点修改</a></p></blockquote><h3 id="1-配置ENV-1"><a href="#1-配置ENV-1" class="headerlink" title="1.配置ENV"></a>1.配置ENV</h3><pre><code>ntpdate 10.20.101.251export MASTER_IP=10.20.140.2</code></pre><h3 id="2-安装Docker-daemon"><a href="#2-安装Docker-daemon" class="headerlink" title="2.安装Docker-daemon"></a>2.安装Docker-daemon</h3><pre><code>yum -y install docker-enginesed -i &quot;s/ExecStart=\/usr\/bin\/dockerd/ExecStart=\/usr\/bin\/dockerd -g=\/yschome\/data\/docker --insecure-registry 10.20.145.240  --registry-mirror=https:\/\/kyyfenk.mirror.acs.aliyun.com --cluster-advertise eth0:2375  --cluster-store etcd:\/\/`echo $MASTER_IP`:2379/&quot; /usr/lib/systemd/system/docker.servicecat /usr/lib/systemd/system/docker.service | grep ExecStartsystemctl daemon-reloadsystemctl start dockersystemctl enable docker</code></pre><h3 id="3-安装Calico"><a href="#3-安装Calico" class="headerlink" title="3.安装Calico"></a>3.安装Calico</h3><pre><code>yum -y install wget wget -O /usr/local/bin/calicoctl http://download.ys-city.com/docker/calicoctl-1.1.0chmod +x /usr/local/bin/calicoctlmkdir -p /etc/calico/cat &lt;&lt;EOF &gt; /etc/calico/calicoctl.cfgapiVersion: v1kind: calicoApiConfigmetadata:spec:  datastoreType: &quot;etcdv2&quot;  etcdEndpoints: &quot;http://`echo $MASTER_IP`:2379&quot;EOFcat /etc/etcd/etcd.conf calicoctl node run  --use-docker-networking-container-labels  --docker-networking-ifprefix=eth --node-image=10.20.145.240/library/calico-node:v1.1.0calicoctl node statusdocker ps -a </code></pre><h3 id="4-启动容器组件"><a href="#4-启动容器组件" class="headerlink" title="4.启动容器组件"></a>4.启动容器组件</h3><pre><code>docker run -ti -d \-p 2375:2375 \--hostname=`hostname` \--label registrator.ignored=true \ --restart=always \--name devops-proxy \-v /var/run/docker.sock:/var/run/docker.sock \-e PORT=2375 \10.20.145.240/library/docker-proxy:latestdocker run -ti -d \--restart=always \--label registrator.ignored=true \--name devops-swarm-agent \ 10.20.145.240/library/swarm:latest  \join --addr `ifconfig eth0|grep inet|grep -v 127.0.0.1|grep -v inet6|awk &apos;{print $2}&apos;|tr -d &apos;addr:&apos;`:2375 etcd://`echo $MASTER_IP`:2379docker run -d \--name=registrator \--restart=always \--net=host \--volume=/var/run/docker.sock:/tmp/docker.sock \10.20.145.240/library/registrator:v1.0 \-internal=true consul://`echo $MASTER_IP`:8500</code></pre><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><blockquote><p>集群安装完成后,默认haproxy会配置根据配置的域名做好代理,如果不希望代理的只需在启动容器时加上 –label registrator.ignored=true 即可,这里了registrator代码做了修改</p></blockquote><blockquote><p>容器使用calico网络后有个问题,即宿主机reboot后docker-daemon无法正常启动,由于容器启动顺序导致循环依赖,解决方法是修改依赖calico网络的容器中的restart策略为no</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;引用&quot;&gt;&lt;a href=&quot;#引用&quot; class=&quot;headerlink&quot; title=&quot;引用&quot;&gt;&lt;/a&gt;引用&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;参考:&lt;a href=&quot;http://hujianxiong.com/2016/09/02/install-docker-swarm-cluster&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://hujianxiong.com/2016/09/02/install-docker-swarm-cluster&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;安装组件&quot;&gt;&lt;a href=&quot;#安装组件&quot; class=&quot;headerlink&quot; title=&quot;安装组件&quot;&gt;&lt;/a&gt;安装组件&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Swarm 使用原生的集群方案&lt;/li&gt;
&lt;li&gt;Etcd key/value存储集群,网络信息等&lt;/li&gt;
&lt;li&gt;Registrator 服务注册&lt;/li&gt;
&lt;li&gt;Calico 网络&lt;/li&gt;
&lt;li&gt;Consul-Haproxy 自动代理后端服务&lt;/li&gt;
&lt;li&gt;Consul Registrator注册的地方也可以使用Etcd,不过有现成的Consul-Haproxy模板可以使用就不替换了,使用Etcd可以替换成confd-Haproxy&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="docker" scheme="http://www.hujianxiong.com/categories/docker/"/>
    
      <category term="swarm" scheme="http://www.hujianxiong.com/categories/docker/swarm/"/>
    
    
      <category term="docker" scheme="http://www.hujianxiong.com/tags/docker/"/>
    
      <category term="calico" scheme="http://www.hujianxiong.com/tags/calico/"/>
    
      <category term="haproxy" scheme="http://www.hujianxiong.com/tags/haproxy/"/>
    
      <category term="etcd" scheme="http://www.hujianxiong.com/tags/etcd/"/>
    
  </entry>
  
  <entry>
    <title>使用dvm解决Docker的Daemon和Client版本不一致问题</title>
    <link href="http://www.hujianxiong.com/2016/12/06/dvm-docker-client-api/"/>
    <id>http://www.hujianxiong.com/2016/12/06/dvm-docker-client-api/</id>
    <published>2016-12-06T06:45:33.000Z</published>
    <updated>2018-05-25T15:02:55.941Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>服务通过Docker Swarm部署后，如果在开发机本地执行类似如下命令：<br>    docker -H tcp://swarm.alibaba.net:8443 exec -it $containerId /bin/bash<br>如果开发机本地Docker版本高于服务器上的版本（这是很容易发生的，稍微Geek的同学是无法容忍本地软件不是最新这一事实的！），就会得到类似如下错误：<br>服务通过Docker Swarm部署后，如果在开发机本地执行类似如下命令：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker -H tcp://swarm.alibaba.net:8443 exec -it $containerId /bin/bash</span><br></pre></td></tr></table></figure><a id="more"></a><p>如果开发机本地Docker版本高于服务器上的版本（这是很容易发生的，稍微Geek的同学是无法容忍本地软件不是最新这一事实的！），就会得到类似如下错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error response from daemon: client is newer than server (client API version: 1.24, server API version: 1.21)</span><br></pre></td></tr></table></figure><p>怎么办？</p><p>你无法要求服务器为此而升级，也无法容忍为此降级本地或者申请一台和服务器的Docker相同版本的ECS——如果你不是这样想的，我很遗憾。</p><p>最合理的办法是本地安装多版本，并且可以随意切换。</p><p>首先给出本地当前版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ docker version</span><br><span class="line">Client:</span><br><span class="line">Version:      1.12.1</span><br><span class="line">API version:  1.24</span><br><span class="line">Go version:   go1.7.1</span><br><span class="line">Git commit:   6f9534c</span><br><span class="line">Built:        Thu Sep 15 11:20:26 2016</span><br><span class="line">OS/Arch:      darwin/amd64</span><br><span class="line">Experimental: true</span><br></pre></td></tr></table></figure><p>安装dvm</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -sL https://download.getcarina.com/dvm/latest/install.sh | sh</span><br><span class="line">source /Users/erichan/.dvm/dvm.sh</span><br></pre></td></tr></table></figure><p>安装和服务器相同版本的Docker，并且换过去</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ dvm install 1.9.0</span><br><span class="line"></span><br><span class="line">$ dvm use 1.9.0                                                                                                                            </span><br><span class="line">Now using Docker 1.9.0</span><br><span class="line"></span><br><span class="line">$ dvm ls                                                                                                                                   </span><br><span class="line">-&gt;  1.9.0</span><br><span class="line">system (1.12.1)</span><br></pre></td></tr></table></figure><p>再来看本地当前版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">lient:</span><br><span class="line">Version:      1.9.0</span><br><span class="line">API version:  1.21</span><br><span class="line">Go version:   go1.4.3</span><br><span class="line">Git commit:   76d6bc9</span><br><span class="line">Built:        Tue Nov  3 19:20:09 UTC 2015</span><br><span class="line">OS/Arch:      darwin/amd64</span><br></pre></td></tr></table></figure><p>最后执行最初的命令。祝好！</p><blockquote><p><a href="https://yq.aliyun.com/articles/61906?spm=5176.100239.topwz.1.Yd996m" target="_blank" rel="noopener">https://yq.aliyun.com/articles/61906?spm=5176.100239.topwz.1.Yd996m</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;服务通过Docker Swarm部署后，如果在开发机本地执行类似如下命令：&lt;br&gt;    docker -H tcp://swarm.alibaba.net:8443 exec -it $containerId /bin/bash&lt;br&gt;如果开发机本地Docker版本高于服务器上的版本（这是很容易发生的，稍微Geek的同学是无法容忍本地软件不是最新这一事实的！），就会得到类似如下错误：&lt;br&gt;服务通过Docker Swarm部署后，如果在开发机本地执行类似如下命令：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker -H tcp://swarm.alibaba.net:8443 exec -it $containerId /bin/bash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="docker" scheme="http://www.hujianxiong.com/categories/docker/"/>
    
    
      <category term="docker" scheme="http://www.hujianxiong.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker监控(Cadvisor+Influxdb+Grafana)</title>
    <link href="http://www.hujianxiong.com/2016/09/07/docker-monitor(cadvisor+influxdb+grafana)/"/>
    <id>http://www.hujianxiong.com/2016/09/07/docker-monitor(cadvisor+influxdb+grafana)/</id>
    <published>2016-09-07T02:09:33.000Z</published>
    <updated>2018-05-25T15:03:22.808Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Docker的火爆程度就不说了，随着docker的生态圈的发展，将原来部署起来很复杂的环境变得非常简单，下面将使用docker部署Cadvisor+Influxdb+Grafana来监控主机系统实时信息，比如cpu,内存等信息以及容器的实时信息.</p><p>首先介绍下几个组件的功能:</p><ol><li>Cadvisor,谷歌公司自己用来监控他们基础设施的一款工具，这个工具厉害之处不仅能监控docker容器的实时信息，而且还能将你的cadvisor这容器所在的主机的系统的实时信息！</li><li>Influxdb,由于cadvisor只是能监控到实时的信息而不能保存，所以我们要使用influxdb来存储实时监控到的信息</li><li>Grafana是纯 Javascript 开发的前端工具，用于访问 InfluxDB，自定义报表、显示图表等。</li></ol><a id="more"></a><h2 id="部署Influxdb"><a href="#部署Influxdb" class="headerlink" title="部署Influxdb"></a>部署Influxdb</h2><blockquote><p>参考 <a href="https://github.com/tutumcloud/influxdb" target="_blank" rel="noopener">https://github.com/tutumcloud/influxdb</a><br>本文使用0.13版本</p></blockquote><pre><code>[root@docker ~]# git clone https://github.com/tutumcloud/influxdb.git[root@docker ~]# cd ~/influxdb/0.13[root@docker ~]# docker build -t=&quot;influxdb:0.13&quot; .[root@docker ~]# docker run -d --name influxdb  \--restart always \-p 8083:8083 -p 8086:8086 \-e ADMIN_USER=&quot;root&quot; \-e INFLUXDB_INIT_PWD=&quot;root&quot; \-e PRE_CREATE_DB=&quot;cadvisor&quot; \10.20.145.240/library/influxdb:0.13</code></pre><blockquote><p>参数说明:<br>ADMIN_USER,INFLUXDB_INIT_PWD,PRE_CREATE_DB初始化容器的时候自动创建数据库及用户和密码</p></blockquote><pre><code>[root@docker 0.13]# docker exec -t -i influxdb /bin/bashroot@70b69d6ca021:/# influxVisit https://enterprise.influxdata.com to  register for updates, InfluxDB server management, and monitoring.Connected to http://localhost:8086 version 0.13.0InfluxDB shell version: 0.13.0&gt; SHOW DATABASESname: databases---------------namecadvisor_internal&gt; SHOW USERSuser    adminroot    true</code></pre><blockquote><p>查看Influxdb服务 <a href="http://10.20.145.240.211:8083" target="_blank" rel="noopener">http://10.20.145.240.211:8083</a></p></blockquote><h2 id="部署Cadvisor"><a href="#部署Cadvisor" class="headerlink" title="部署Cadvisor"></a>部署Cadvisor</h2><blockquote><p>在需要监控的节点上都启动一个cadvisor容器,参考:<a href="https://github.com/google/cadvisor" target="_blank" rel="noopener">https://github.com/google/cadvisor</a></p></blockquote><pre><code>[root@docker ~]# docker run -d \--restart=always \--volume=/:/rootfs:ro \--volume=/var/run:/var/run:rw \--volume=/sys:/sys:ro \--volume=/var/lib/docker/:/var/lib/docker:ro \--publish=8080:8080 \-h $HOSTNAME \--detach=true \--name=cadvisor google/cadvisor:latest \-docker_only \-storage_driver=influxdb \-storage_driver_db=cadvisor \-storage_driver_host=10.20.145.211:8086</code></pre><blockquote><p>参数说明 docker_only:cadvisor容器只监控容器<br>打开节点上的8080端口就能看到当前节点的实时监控了</p></blockquote><h2 id="部署Grafana"><a href="#部署Grafana" class="headerlink" title="部署Grafana"></a>部署Grafana</h2><pre><code>[root@docker ~]# docker run -d \-p 3000:3000 \--restart always \-e INFLUXDB_HOST=10.20.145.211 \-e INFLUXDB_PORT=8086 \-e INFLUXDB_NAME=cadvisor \-e INFLUXDB_USER=root \-e INFLUXDB_PASS=root \--link influxdb:influxdb \--name grafana 10.20.145.240/library/grafana</code></pre><blockquote><p>浏览器访问 10.20.145.211:3000,图表的配置比较麻烦,可以参考:<a href="http://play.grafana.org/" target="_blank" rel="noopener">http://play.grafana.org/</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;Docker的火爆程度就不说了，随着docker的生态圈的发展，将原来部署起来很复杂的环境变得非常简单，下面将使用docker部署Cadvisor+Influxdb+Grafana来监控主机系统实时信息，比如cpu,内存等信息以及容器的实时信息.&lt;/p&gt;
&lt;p&gt;首先介绍下几个组件的功能:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Cadvisor,谷歌公司自己用来监控他们基础设施的一款工具，这个工具厉害之处不仅能监控docker容器的实时信息，而且还能将你的cadvisor这容器所在的主机的系统的实时信息！&lt;/li&gt;
&lt;li&gt;Influxdb,由于cadvisor只是能监控到实时的信息而不能保存，所以我们要使用influxdb来存储实时监控到的信息&lt;/li&gt;
&lt;li&gt;Grafana是纯 Javascript 开发的前端工具，用于访问 InfluxDB，自定义报表、显示图表等。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="docker" scheme="http://www.hujianxiong.com/categories/docker/"/>
    
      <category term="monitor" scheme="http://www.hujianxiong.com/categories/docker/monitor/"/>
    
    
      <category term="docker" scheme="http://www.hujianxiong.com/tags/docker/"/>
    
      <category term="cadvisor" scheme="http://www.hujianxiong.com/tags/cadvisor/"/>
    
      <category term="influxdb" scheme="http://www.hujianxiong.com/tags/influxdb/"/>
    
      <category term="grafana" scheme="http://www.hujianxiong.com/tags/grafana/"/>
    
  </entry>
  
  <entry>
    <title>使用Graylog2收集Docker日志</title>
    <link href="http://www.hujianxiong.com/2016/09/06/graylog2-docker-logs/"/>
    <id>http://www.hujianxiong.com/2016/09/06/graylog2-docker-logs/</id>
    <published>2016-09-06T09:45:33.000Z</published>
    <updated>2018-05-25T15:04:01.594Z</updated>
    
    <content type="html"><![CDATA[<p>Graylog2 是一个开源的日志存储系统,是由java语言编写的server,能够接收TCP,UDP,AMQP的协议发送的日志信息,并且基于mongodb数据库服务器快速存储,能够通过一个基于ruby编写的web管理界面,让轻松管理你的日志。</p><blockquote><p>参考:<a href="http://docs.graylog.org/en/2.1/pages/installation/docker.html#requirements" target="_blank" rel="noopener">http://docs.graylog.org/en/2.1/pages/installation/docker.html#requirements</a></p></blockquote><h2 id="所需组件"><a href="#所需组件" class="headerlink" title="所需组件"></a>所需组件</h2><ol><li>mongodb</li><li>elasticsearch</li><li>graylog2</li></ol><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><blockquote><p>使用Docker-compose部署<br>docker-compose安装,参考:<a href="http://hujianxiong.com/linuxan-zhuang-docker-compose/" target="_blank" rel="noopener">http://hujianxiong.com/linuxan-zhuang-docker-compose/</a></p></blockquote><h4 id="docker-compose文件"><a href="#docker-compose文件" class="headerlink" title="docker-compose文件:"></a>docker-compose文件:</h4><pre><code>version: &apos;2&apos;services:  mongo:    image: &quot;mongo:3&quot;    restart: always    volumes:      - /yschome/data/graylog/data/mongo:/data/db  elasticsearch:    image: &quot;elasticsearch:2&quot;    command: &quot;elasticsearch -Des.cluster.name=&apos;graylog&apos;&quot;    volumes:       - /yschome/data/graylog/data/elasticsearch:/usr/share/elasticsearch/data    restart: always  graylog:    image: graylog2/server    volumes:      - /yschome/data/graylog/data/journal:/usr/share/graylog/data/journal      - /yschome/data/graylog/config:/usr/share/graylog/data/config    environment:      GRAYLOG_PASSWORD_SECRET: somepasswordpepper      GRAYLOG_ROOT_PASSWORD_SHA2: 8c6976e5b5410415bde908bd4dee15dfb167a9c873fc4bb8a81f6f2ab448a918      #GRAYLOG_WEB_ENDPOINT_URI: http://0.0.0.0:9000/api/      GRAYLOG_REST_TRANSPORT_URI: http://10.20.145.65:12900    depends_on:      - mongo      - elasticsearch    links:      - mongo:mongo      - elasticsearch:elasticsearch    ports:      - &quot;9000:9000&quot;      - &quot;12900:12900&quot;      - &quot;12201/udp:12201/udp&quot;      - &quot;1514/udp:1514/udp&quot;    restart: always</code></pre><h2 id="下载配置文件"><a href="#下载配置文件" class="headerlink" title="下载配置文件"></a>下载配置文件</h2><pre><code>[root@amumu ~]# mkdir -p /yschome/data/graylog/config[root@amumu ~]# cd /yschome/data/graylog/config[root@amumu config]# wget https://raw.githubusercontent.com/Graylog2/graylog2-images/2.1/docker/config/graylog.conf[root@amumu config]# wget https://raw.githubusercontent.com/Graylog2/graylog2-images/2.1/docker/config/log4j2.xml</code></pre><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><pre><code>[root@amumu ~]# docker-compose up -d</code></pre><h2 id="Graylog配置接收日志"><a href="#Graylog配置接收日志" class="headerlink" title="Graylog配置接收日志"></a>Graylog配置接收日志</h2><blockquote><p>登录 <a href="http://10.20.145.210:9000" target="_blank" rel="noopener">http://10.20.145.210:9000</a> admin/admin<br>配置system==&gt;input==&gt;select input ===&gt;GELF UDP</p></blockquote><h2 id="修改Docker-daemon启动参数"><a href="#修改Docker-daemon启动参数" class="headerlink" title="修改Docker daemon启动参数"></a>修改Docker daemon启动参数</h2><blockquote><p>–log-driver=gelf<br>–log-opt gelf-address=udp://10.20.145.210:12201<br>–log-opt gelf-compression-type=gzip<br>–log-opt gelf-compression-level=1<br>–log-opt tag=”test01_env”</p></blockquote><h4 id="重启daemon"><a href="#重启daemon" class="headerlink" title="重启daemon"></a>重启daemon</h4><pre><code>[root@amumu ~]# systemctl daemon-reload[root@amumu ~]# systemctl restart docker</code></pre><blockquote><p>启动容器后在Graylog管理界面就可以看到接收的日志了</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Graylog2 是一个开源的日志存储系统,是由java语言编写的server,能够接收TCP,UDP,AMQP的协议发送的日志信息,并且基于mongodb数据库服务器快速存储,能够通过一个基于ruby编写的web管理界面,让轻松管理你的日志。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;参考:&lt;a href=&quot;http://docs.graylog.org/en/2.1/pages/installation/docker.html#requirements&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://docs.graylog.org/en/2.1/pages/installation/docker.html#requirements&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;所需组件&quot;&gt;&lt;a href=&quot;#所需组件&quot; class=&quot;headerlink&quot; title=&quot;所需组件&quot;&gt;&lt;/a&gt;所需组件&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;mongodb&lt;/li&gt;
&lt;li&gt;elasticsearch&lt;/li&gt;
&lt;li&gt;graylog2&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="docker" scheme="http://www.hujianxiong.com/categories/docker/"/>
    
      <category term="logs" scheme="http://www.hujianxiong.com/categories/docker/logs/"/>
    
    
      <category term="docker" scheme="http://www.hujianxiong.com/tags/docker/"/>
    
      <category term="graylog2" scheme="http://www.hujianxiong.com/tags/graylog2/"/>
    
  </entry>
  
  <entry>
    <title>Linux安装docker-compose</title>
    <link href="http://www.hujianxiong.com/2016/09/06/installl-docker-compose/"/>
    <id>http://www.hujianxiong.com/2016/09/06/installl-docker-compose/</id>
    <published>2016-09-06T01:45:33.000Z</published>
    <updated>2018-05-26T15:23:36.418Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>使用pip安装docker-compose</p></blockquote><h2 id="1-安装setuptools软件包"><a href="#1-安装setuptools软件包" class="headerlink" title="1.安装setuptools软件包"></a>1.安装setuptools软件包</h2><blockquote><p>下载:</p></blockquote><pre><code>[root@amumu ~]# wget https://pypi.python.org/packages/32/3c/e853a68b703f347f5ed86585c2dd2828a83252e1216c1201fa6f81270578/setuptools-26.1.1.tar.gz#md5=0744ee90ad266fb117d59f94334185d0</code></pre><blockquote><p> 解压:</p></blockquote><pre><code>[root@amumu ~]# tar -zxvf setuptools-26.1.1.tar.gz    [root@amumu ~]# cd setuptools-26.1.1</code></pre><a id="more"></a><blockquote><p>编译:</p></blockquote><pre><code>[root@amumu setuptools-26.1.1]# python setup.py buildrunning buildrunning build_py</code></pre><blockquote><p>安装:</p></blockquote><pre><code>[root@amumu setuptools-26.1.1]# python setup.py install</code></pre><h2 id="2-安装pip"><a href="#2-安装pip" class="headerlink" title="2.安装pip"></a>2.安装pip</h2><blockquote><p>下载:</p></blockquote><pre><code>[root@amumu ~]# wget https://pypi.python.org/packages/e7/a8/7556133689add8d1a54c0b14aeff0acb03c64707ce100ecd53934da1aa13/pip-8.1.2.tar.gz#md5=87083c0b9867963b29f7aba3613e8f4a</code></pre><blockquote><p>解压:</p></blockquote><pre><code>[root@amumu ~]# tar -zxvf pip-8.1.2.tar.gz[root@amumu ~]# cd pip-8.1.2</code></pre><blockquote><p>安装:</p></blockquote><pre><code>[root@amumu ~]# python setup.py  install</code></pre><h2 id="3-安装docker-compose"><a href="#3-安装docker-compose" class="headerlink" title="3.安装docker-compose"></a>3.安装docker-compose</h2><pre><code>[root@amumu ~]# pip install docker-compose</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;使用pip安装docker-compose&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;1-安装setuptools软件包&quot;&gt;&lt;a href=&quot;#1-安装setuptools软件包&quot; class=&quot;headerlink&quot; title=&quot;1.安装setuptools软件包&quot;&gt;&lt;/a&gt;1.安装setuptools软件包&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;下载:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;[root@amumu ~]# wget https://pypi.python.org/packages/32/3c/e853a68b703f347f5ed86585c2dd2828a83252e1216c1201fa6f81270578/setuptools-26.1.1.tar.gz#md5=0744ee90ad266fb117d59f94334185d0
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt; 解压:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;[root@amumu ~]# tar -zxvf setuptools-26.1.1.tar.gz    
[root@amumu ~]# cd setuptools-26.1.1
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="docker" scheme="http://www.hujianxiong.com/categories/docker/"/>
    
      <category term="docker-compose" scheme="http://www.hujianxiong.com/categories/docker/docker-compose/"/>
    
    
      <category term="docker" scheme="http://www.hujianxiong.com/tags/docker/"/>
    
      <category term="docker-compose" scheme="http://www.hujianxiong.com/tags/docker-compose/"/>
    
  </entry>
  
  <entry>
    <title>Docker Swarm 集群搭建</title>
    <link href="http://www.hujianxiong.com/2016/09/02/install-docker-swarm-cluster/"/>
    <id>http://www.hujianxiong.com/2016/09/02/install-docker-swarm-cluster/</id>
    <published>2016-09-02T15:09:33.000Z</published>
    <updated>2018-05-25T15:04:46.631Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><ul><li>宿主机操作系统<ul><li><code>CentOS Linux release 7.2.1511 (Core)</code></li></ul></li><li>Docker版本<ul><li><code>Server Version: 1.12.0</code></li></ul></li><li>Swarm版本:<ul><li><code>Server Version: swarm/1.2.4</code></li></ul></li><li>Consul版本:<ul><li><code>Consul v0.5.2</code></li></ul></li><li><p>IP规划:</p><ul><li><code>10.20.145.46 ~ 10.20.145.48    #Consul集群</code></li><li><code>10.20.145.49 ~ 10.20.145.50    #Swarm Manager</code></li><li><code>10.20.145.51 ~ 10.20.145.63    #Swarm Agent</code></li></ul><a id="more"></a></li></ul><h2 id="集群所需要的组件"><a href="#集群所需要的组件" class="headerlink" title="集群所需要的组件"></a>集群所需要的组件</h2><blockquote><p>使用Shipyard Docker资源管理平台<br>参考:<a href="http://www.shipyard-project.com/docs/deploy/manual/" target="_blank" rel="noopener">http://www.shipyard-project.com/</a></p></blockquote><ul><li>Consul  &nbsp;  主要用于服务发现以及共享配置,如创建multi-host-network</li><li>RethinkDB &nbsp; key-value存储系统,用于存储Swarm集群信息</li><li>Registrator  &nbsp;  服务自动注册,需在每个节点上部署</li><li>Haproxy  &nbsp;  配合Registrator实现服务自动发现和自动代理</li><li>Cadvisor  &nbsp;  google开源的docker容器资源监控软件</li><li>InfluxDB  &nbsp;  存储Cadvisor监控数据</li><li>Grafana  &nbsp;  读取InfluxDB数据,显示监控图表</li></ul><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="1-测试环境关闭防火墙-Selinux"><a href="#1-测试环境关闭防火墙-Selinux" class="headerlink" title="1.测试环境关闭防火墙,Selinux"></a>1.测试环境关闭防火墙,Selinux</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# systemctl stop firewalld</span><br><span class="line">[root@amumu ~]# systemctl disable firewalld</span><br><span class="line">[root@amumu ~]# sed -i &quot;s/enforcing/disabled/&quot; /etc/selinux/config</span><br><span class="line">[root@amumu ~]# sed -i &quot;s/enforcing/disabled/&quot; /etc/sysconfig/selinux</span><br></pre></td></tr></table></figure><h3 id="2-Docker安装"><a href="#2-Docker安装" class="headerlink" title="2.Docker安装"></a>2.Docker安装</h3><blockquote><p>配置阿里Docker YUM源<br>说明:在所有IP节点上执行</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# tee /etc/yum.repos.d/docker.repo &lt;&lt;-&apos;EOF&apos;</span><br><span class="line">[docker-main-repo]</span><br><span class="line">name=Docker main Repository</span><br><span class="line">baseurl=http://mirrors.aliyun.com/docker-engine/yum/repo/main/centos/7</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirrors.aliyun.com/docker-engine/yum/gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><blockquote><p>安装Docker<br>说明:在所有IP节点上执行</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# yum install -y docker-engine</span><br><span class="line">[root@amumu ~]# yum list installed | grep docker</span><br><span class="line">docker-engine.x86_64                  1.12.1-1.el7.centos             @docker-main-repo</span><br><span class="line">docker-engine-selinux.noarch          1.12.1-1.el7.centos             @docker-main-repo</span><br></pre></td></tr></table></figure><blockquote><p>配置Docker Consul节点上(10.20.145.46~10.20.145.48)<br>1.更换docker默认存储位置为/yschome/data/docker</p></blockquote><blockquote><p>2.配置私有仓库地址为10.20.145.240</p></blockquote><blockquote><p>3.配置加速器–registry-mirror(可选)</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# sed -i &apos;s/ExecStart=\/usr\/bin\/dockerd/ExecStart=\/usr\/bin\/dockerd -g=\/yschome\/data\/docker --insecure-registry 10.20.145.240  --registry-mirror=https:\/\/kyyfenk.mirror.acs.aliyun.com/&apos; /usr/lib/systemd/system/docker.service</span><br><span class="line">[root@amumu ~]# systemctl daemon-reload</span><br><span class="line">[root@amumu ~]# systemctl start docker</span><br><span class="line">[root@amumu ~]# systemctl enable docker</span><br></pre></td></tr></table></figure><blockquote><p>配置Docker Swarm集群上(10.20.145.48~10.20.145.63)<br>1.更换docker默认存储位置为/yschome/data/docker</p></blockquote><blockquote><p>2.配置私有仓库地址为10.20.145.240</p></blockquote><blockquote><p>3.配置加速器–registry-mirror(可选)</p></blockquote><blockquote><p>4.–cluster-advertise 配置的是本Docker Daemon实例在cluster中的地址</p></blockquote><blockquote><p>5.–cluster-store 配置的是Cluster的分布式KV store的访问地址</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# sed -i &apos;s/ExecStart=\/usr\/bin\/dockerd/ExecStart=\/usr\/bin\/dockerd -g=\/yschome\/data\/docker --insecure-registry 10.20.145.240  --registry-mirror=https:\/\/kyyfenk.mirror.acs.aliyun.com --cluster-advertise eth0:2375 --cluster-store consul:\/\/10.20.145.46:8500/&apos; /usr/lib/systemd/system/docker.service</span><br><span class="line">[root@amumu ~]# systemctl daemon-reload</span><br><span class="line">[root@amumu ~]# systemctl start docker</span><br><span class="line">[root@amumu ~]# systemctl enable docker</span><br></pre></td></tr></table></figure><h3 id="3-Consul集群安装"><a href="#3-Consul集群安装" class="headerlink" title="3.Consul集群安装"></a>3.Consul集群安装</h3><blockquote><p>10.20.145.46启动Consul master容器</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# docker run -d \</span><br><span class="line">-p 8300:8300 \</span><br><span class="line">-p 8301:8301 \</span><br><span class="line">-p 8301:8301/udp \</span><br><span class="line">-p 8302:8302 \</span><br><span class="line">-p 8302:8302/udp \</span><br><span class="line">-p 8400:8400 \</span><br><span class="line">-p 8500:8500 \</span><br><span class="line">-p 8600:53 \</span><br><span class="line">-p 53:53/udp \</span><br><span class="line">-v /yschome/data/consul:/data \</span><br><span class="line">-h $HOSTNAME \</span><br><span class="line">--restart=always \</span><br><span class="line">--name=consul 10.20.145.240/library/consul:0.5.2 \ </span><br><span class="line">-server -bootstrap -ui-dir=/ui -dc=my-consul -advertise 10.20.145.46 -client 0.0.0.0</span><br></pre></td></tr></table></figure><blockquote><p>10.20.145.47启动Consule Agent容器,需增加 -join 参数</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# docker run -d \</span><br><span class="line">-p 8300:8300 \</span><br><span class="line">-p 8301:8301 \</span><br><span class="line">-p 8301:8301/udp \</span><br><span class="line">-p 8302:8302 \</span><br><span class="line">-p 8302:8302/udp \</span><br><span class="line">-p 8400:8400 \</span><br><span class="line">-p 8500:8500 \</span><br><span class="line">-v /yschome/data/consul:/data \</span><br><span class="line">-h $HOSTNAME \</span><br><span class="line">--restart=always \</span><br><span class="line">--name=consul 10.20.145.240/library/consul:0.5.2 \</span><br><span class="line">-server -join 10.20.145.46 -dc=my-consul -advertise 10.20.145.47 -client 0.0.0.0</span><br></pre></td></tr></table></figure><blockquote><p> 10.20.145.48启动Consule Agent容器,需增加 -join 参数,并且在次节点上启动Haproxy容器做自动代理,Haproxy可在所有节点上都启动,在前端配置一个LVS可做HA,用Haproxy可实现服务不用映射主机端口即可做代理访问,这样就不用管理端口了,后续再完善,本次测试环境就单节点即可.</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# docker run -d \</span><br><span class="line">-p 8300:8300 \</span><br><span class="line">-p 8301:8301 \</span><br><span class="line">-p 8301:8301/udp \</span><br><span class="line">-p 8302:8302 \</span><br><span class="line">-p 8302:8302/udp \</span><br><span class="line">-p 8400:8400 \</span><br><span class="line">-p 8500:8500 \</span><br><span class="line">-v /yschome/data/consul:/data \</span><br><span class="line">-h $HOSTNAME \</span><br><span class="line">--restart=always \</span><br><span class="line">--name=consul 10.20.145.240/library/consul:0.5.2 \</span><br><span class="line">-server -join 10.20.145.46  -dc=my-consul -advertise 10.20.145.48 -client 0.0.0.0</span><br><span class="line">    </span><br><span class="line">[root@amumu ~]# docker run  -d -p 80:80 --name haproxy  \</span><br><span class="line">--restart always  \</span><br><span class="line">-e HAPROXY_DOMAIN=test01.hujianxiong.com \</span><br><span class="line">-e CONSUL_CONNECT=10.20.140.20:8500 \</span><br><span class="line">10.20.145.240/library/haproxy:1.0</span><br></pre></td></tr></table></figure><p><em>Consul集群配置完成,打开浏览器访问<a href="http://10.20.145.46:8500" target="_blank" rel="noopener">http://10.20.145.46:8500</a></em></p><h3 id="4-Swarm集群和Shipyard-DockerUI资源管理平台安装"><a href="#4-Swarm集群和Shipyard-DockerUI资源管理平台安装" class="headerlink" title="4.Swarm集群和Shipyard DockerUI资源管理平台安装"></a>4.Swarm集群和Shipyard DockerUI资源管理平台安装</h3><blockquote><p>10.20.145.49节点安装Swarm Manager,Rethinkdb,Proxy,Shipyard</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# docker run  -d \</span><br><span class="line">-p 8080:8080 \</span><br><span class="line">-h $HOSTNAME \</span><br><span class="line">-v /yschome/data/rethinkdb:/data \</span><br><span class="line">--restart=always \</span><br><span class="line">--name devops-rethinkdb 10.20.145.240/library/rethinkdb:latest</span><br><span class="line"></span><br><span class="line">[root@amumu ~]# docker run  -d \</span><br><span class="line">-p 2375:2375 \</span><br><span class="line">--hostname=$HOSTNAME \</span><br><span class="line">--restart=always \</span><br><span class="line">--name devops-proxy \</span><br><span class="line">-v /var/run/docker.sock:/var/run/docker.sock \</span><br><span class="line">-e PORT=2375 \</span><br><span class="line">10.20.145.240/library/docker-proxy:latest</span><br><span class="line"></span><br><span class="line">[root@amumu ~]# docker run  -d \</span><br><span class="line">--restart=always -p 3375:3375 \</span><br><span class="line">--name devops-swarm-manager 10.20.145.240/library/swarm:1.2.4 \</span><br><span class="line">manage  --replication \</span><br><span class="line">--addr 10.20.145.49:3375 \</span><br><span class="line">--host tcp://0.0.0.0:3375  consul://10.20.145.46:8500</span><br><span class="line"></span><br><span class="line">[root@amumu ~]# docker run  -d \</span><br><span class="line">--restart=always \</span><br><span class="line">--name devops-controller \</span><br><span class="line">--link devops-rethinkdb:rethinkdb \</span><br><span class="line">--link devops-swarm-manager:swarm \</span><br><span class="line">-p 80:8080 \</span><br><span class="line">10.20.145.240/library/shipyard:latest \</span><br><span class="line">server \</span><br><span class="line">-d tcp://swarm:3375</span><br></pre></td></tr></table></figure><p><em>访问地址:</em></p><p><em>Rethinkdb:<a href="http://10.20.145.49:8080/" target="_blank" rel="noopener">http://10.20.145.49:8080/</a></em></p><p><em>Shipyard:<a href="http://10.20.145.49" target="_blank" rel="noopener">http://10.20.145.49</a> admin/shipyard</em></p><blockquote><p>10.20.145.50安装Swarm Manager</p></blockquote> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# docker run -d \</span><br><span class="line">--restart=always -p 3375:3375 \</span><br><span class="line">--name devops-swarm-manager 10.20.145.240/library/swarm:1.2.4 \</span><br><span class="line">manage  --replication \</span><br><span class="line">--addr 10.20.145.50:3375 \</span><br><span class="line">--host tcp://0.0.0.0:3375  consul://10.20.145.46:8500</span><br><span class="line"></span><br><span class="line">[root@amumu ~]# docker run  -d \</span><br><span class="line">-p 2375:2375 \</span><br><span class="line">--hostname=$HOSTNAME \</span><br><span class="line">--restart=always \</span><br><span class="line">--name devops-proxy \</span><br><span class="line">-v /var/run/docker.sock:/var/run/docker.sock \</span><br><span class="line">-e PORT=2375 \</span><br><span class="line">10.20.145.240/library/docker-proxy:latest</span><br></pre></td></tr></table></figure><blockquote><p>配置Swarm Agent节点<br>10.20.145.51~10.20.145.63需启动Proxy,Swarm Agent,Registrator</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@amumu ~]# docker run -ti -d \</span><br><span class="line">-p 2375:2375 \</span><br><span class="line">--hostname=$HOSTNAME \</span><br><span class="line">--restart=always \</span><br><span class="line">--name devops-proxy \</span><br><span class="line">-v /var/run/docker.sock:/var/run/docker.sock \</span><br><span class="line">-e PORT=2375 \</span><br><span class="line">10.20.145.240/library/docker-proxy:latest</span><br><span class="line"></span><br><span class="line">[root@amumu ~]# docker run -ti -d \</span><br><span class="line">--restart=always \</span><br><span class="line">--name devops-swarm-agent \</span><br><span class="line">10.20.145.240/library/swarm:1.2.4 \</span><br><span class="line">join --addr `ifconfig eth0|grep inet|grep -v 127.0.0.1|grep -v inet6|awk &apos;&#123;print $2&#125;&apos;|tr -d &quot;addr:&quot;`:2375 consul://10.20.145.46:8500</span><br><span class="line"></span><br><span class="line">[root@amumu ~]# docker run -d \</span><br><span class="line">--restart=always \</span><br><span class="line">--name=devops-registrator \</span><br><span class="line">--net=host \</span><br><span class="line">-v /var/run/docker.sock:/tmp/docker.sock 10.20.145.240/library/registrator \</span><br><span class="line">-ip `ifconfig eth0|grep inet|grep -v 127.0.0.1|grep -v inet6|awk &apos;&#123;print $2&#125;&apos;|tr -d &quot;addr:&quot;` consul://10.20.145.46:8500</span><br></pre></td></tr></table></figure><h3 id="5-Docker监控-Cadvisor-Influxdb-Grafana"><a href="#5-Docker监控-Cadvisor-Influxdb-Grafana" class="headerlink" title="5.Docker监控(Cadvisor+Influxdb+Grafana)"></a>5.Docker监控(Cadvisor+Influxdb+Grafana)</h3><blockquote><p>详见:<a href="http://hujianxiong.com/docker-monitor/" target="_blank" rel="noopener">http://hujianxiong.com/docker-monitor/</a></p></blockquote><h3 id="6-使用Graylog2收集Docker日志"><a href="#6-使用Graylog2收集Docker日志" class="headerlink" title="6.使用Graylog2收集Docker日志"></a>6.使用Graylog2收集Docker日志</h3><blockquote><p>详见:<a href="http://hujianxiong.com/graylog2-docker/" target="_blank" rel="noopener">http://hujianxiong.com/graylog2-docker/</a></p></blockquote><p>*集群搭建完成,本文主要用于学习所用,仅供参考.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;环境配置&quot;&gt;&lt;a href=&quot;#环境配置&quot; class=&quot;headerlink&quot; title=&quot;环境配置&quot;&gt;&lt;/a&gt;环境配置&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;宿主机操作系统&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CentOS Linux release 7.2.1511 (Core)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Docker版本&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Server Version: 1.12.0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Swarm版本:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Server Version: swarm/1.2.4&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Consul版本:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Consul v0.5.2&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;IP规划:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;10.20.145.46 ~ 10.20.145.48    #Consul集群&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;10.20.145.49 ~ 10.20.145.50    #Swarm Manager&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;10.20.145.51 ~ 10.20.145.63    #Swarm Agent&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="docker" scheme="http://www.hujianxiong.com/categories/docker/"/>
    
      <category term="swarm" scheme="http://www.hujianxiong.com/categories/docker/swarm/"/>
    
    
      <category term="docker" scheme="http://www.hujianxiong.com/tags/docker/"/>
    
      <category term="swarm" scheme="http://www.hujianxiong.com/tags/swarm/"/>
    
  </entry>
  
</feed>
